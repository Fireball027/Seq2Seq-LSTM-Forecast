## Overview

This project applies a powerful **Encoderâ€“Decoder LSTM (Long Short-Term Memory)** architecture for **multi-step forecasting** on time series data. Using the classic **Airline Passengers** dataset, the model predicts future passenger counts based on historical trends.

---

## ğŸš€ Key Features

âœ… **Multi-Step Forecasting** â€” Predicts multiple future time steps (e.g., 6 months ahead).
âœ… **Data Normalization** â€” Scales data for better neural network performance.
âœ… **Encoderâ€“Decoder LSTM** â€” Implements sequence-to-sequence learning for time series.
âœ… **Early Stopping** â€” Stops training when the model stops improving.
âœ… **Evaluation** â€” Calculates RMSE for each forecast step.
âœ… **Diagnostic Plots** â€” Visualizes actual vs. predicted, residuals, forecast horizons, and more.

---

## ğŸ“‚ Project Files

### `airline-passengers.csv`

This dataset contains monthly international airline passenger numbers (1949â€“1960).

* **Column:**

  * `#Passengers` â€” number of passengers per month.

---

### `encoder_decoder_lstm.py`

This script:

* Loads and **normalizes data**.
* Creates **supervised learning sequences**.
* Defines and trains an **Encoderâ€“Decoder LSTM**.
* **Evaluates performance**.
* Generates **diagnostic plots**.
* Saves the **trained model and scaler**.

---

## ğŸ§© Example Code Snippet

```python
# Create supervised sequences
X_train, y_train = split_sequence(train, N_STEPS_IN, N_STEPS_OUT)

# Define Encoderâ€“Decoder model
encoder_inputs = Input(shape=(N_STEPS_IN, 1))
encoder_lstm = LSTM(100, activation='relu')(encoder_inputs)
repeat_vector = RepeatVector(N_STEPS_OUT)(encoder_lstm)
decoder_lstm = LSTM(100, activation='relu', return_sequences=True)(repeat_vector)
decoder_outputs = TimeDistributed(Dense(1))(decoder_lstm)

model = Model(inputs=encoder_inputs, outputs=decoder_outputs)
model.compile(optimizer='adam', loss='mse')
model.fit(X_train, y_train, ...)
```

---

## âš™ï¸ How to Run

1ï¸âƒ£ **Install Dependencies**

```bash
pip install numpy pandas matplotlib seaborn scikit-learn keras joblib
```

2ï¸âƒ£ **Run the Script**

```bash
python encoder_decoder_lstm.py
```

3ï¸âƒ£ **View Results**

* Inspect **training logs**, **RMSE scores**, and **plots**.
* Saved files:

  * `encoder_decoder_lstm.h5` â€” **trained model**.
  * `scaler.save` â€” **saved scaler** for future inference.

---

## ğŸ”® Future Enhancements

* **Attention Mechanism:** Improve context learning for long sequences.
* **Bidirectional LSTM:** Enhance understanding of sequential patterns.
* **Walk-Forward Validation:** Implement live forecasting.
* **Streamlit App:** Deploy as an interactive forecasting dashboard.

---

## âœ… Conclusion

This **Encoderâ€“Decoder LSTM** pipeline is a solid baseline for **multi-step time series forecasting**.
Itâ€™s fully extensible for other **univariate** or even **multivariate time series tasks**.

## Happy Forecasting! ğŸš€ğŸ“ˆ
